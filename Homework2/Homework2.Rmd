---
title: "Homework 2"
author: Anthony DeNiro
date: February 7, 2020
output: github_document
---

libraries
```{r}
library(ElemStatLearn)
library(magrittr)
library(dplyr)
library(glmnet)
```

read in data
```{r}
data('prostate')
```

training and testing sets
```{r}
## split prostate into testing and training subsets
prostate_train <- prostate %>%
  filter(train == TRUE) %>% 
  select(-train)


prostate_test <- prostate %>%
  filter(train == FALSE) %>% 
  select(-train)
```

correlation coeficients
```{r}
cor(prostate_train[1:8])
```



linear model fitting lpsa outcome
```{r}
fit <- lm(lpsa ~ ., data = prostate_train)
```

computing test error with L2 loss function for linear model
```{r}
## functions to compute testing/training error w/lm
L2_loss <- function(y, yhat)
  (y-yhat)^2

error <- function(dat, fit, loss=L2_loss)
  mean(loss(dat$lpsa, predict(fit, newdata=dat)))


## testing error
error(prostate_test, fit)
```

ridge model fitting with lpsa outcome
```{r}
## use glmnet to fit lasso
## glmnet fits using penalized L2 loss
## first create an input matrix and output vector
form  <- lpsa ~ 0 + lweight + age + lbph + lcp + pgg45 + lcavol + svi + gleason # 0 gives no intercept so glmnet doesnt penalize the intercept
x_inp <- model.matrix(form, data=prostate_train)
y_out <- prostate_train$lpsa

#?glmnet()
fit_ridge <- glmnet(x=x_inp, y=y_out, lambda= seq(0.75,0,-0.05), alpha = 0)
#print(fit_ridge$beta)
```


```{r}
## plot path diagram
plot(x=range(fit_ridge$lambda),
     y=range(as.matrix(fit_ridge$beta)),
     type='n',
     xlab=expression(lambda),
     ylab='Coefficients')
for(i in 1:nrow(fit_ridge$beta)) {
  points(x=fit_ridge$lambda, y=fit_ridge$beta[i,], pch=19, col='#00000055')
  lines(x=fit_ridge$lambda, y=fit_ridge$beta[i,], col='#00000055')
}
abline(h=0, lty=3, lwd=2)
```

```{r}
## functions to compute testing/training error with glmnet
error_ridge <- function(dat, fit, lam, form, loss=L2_loss) {
  x_inp <- model.matrix(form, data=dat)
  y_out <- dat$lpsa
  y_hat <- predict(fit, newx=x_inp, s=lam)  ## see predict.elnet
  mean(loss(y_out, y_hat))
}

## compute training and testing errors as function of lambda
err_train_1 <- sapply(fit_ridge$lambda, function(lam) 
  error_ridge(prostate_train, fit_ridge, lam, form))

err_test_1 <- sapply(fit_ridge$lambda, function(lam) 
  error_ridge(prostate_test, fit_ridge, lam, form))

## plot test/train error
plot(x=range(fit_ridge$lambda),
     y=range(c(err_train_1, err_test_1)),
     type='n',
     xlab=expression(lambda),
     ylab='train/test error')
points(fit_ridge$lambda, err_train_1, pch=19, type='b', col='darkblue')
points(fit_ridge$lambda, err_test_1, pch=19, type='b', col='darkred')
legend('topleft', c('train','test'), lty=1, pch=19,
       col=c('darkblue','darkred'), bty='n')

colnames(fit_ridge$beta) <- paste('lam =', fit_ridge$lambda)
#print(fit_ridge$beta %>% as.matrix)
```

